{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0702cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored, cumulative_dynamic_auc\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "india = pd.read_csv('india_clean.csv')\n",
    "jordan = pd.read_csv('jordan_clean.csv')\n",
    "florida = pd.read_csv('florida_clean.csv')\n",
    "california = pd.read_csv('california_clean.csv')\n",
    "\n",
    "# Ensure LOS >= 1\n",
    "for df in [india, jordan, florida, california]:\n",
    "    if \"los\" in df.columns:\n",
    "        df[\"los\"] = df[\"los\"].clip(lower=1)\n",
    "\n",
    "# Registry\n",
    "dataset_registry = {\n",
    "    \"India\": india,\n",
    "    \"Jordan\": jordan,\n",
    "    \"Florida\": florida,\n",
    "    \"California\": california\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a556e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored, cumulative_dynamic_auc\n",
    "from scipy.stats import wilcoxon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Utility functions ---\n",
    "def to_sksurv_y(df):\n",
    "    return np.array([(bool(e), t) for e, t in zip(df['event'], df['los'])],\n",
    "                    dtype=[('event', bool), ('time', float)])\n",
    "\n",
    "def to_X(df):\n",
    "    return df[['age', 'sex', 'gcs']].values\n",
    "\n",
    "def compute_dynamic_auc_v(y_train, y_test, risk, time_points):\n",
    "    auc_curve = []\n",
    "    for t in time_points:\n",
    "        _, auc = cumulative_dynamic_auc(y_train, y_test, risk, times=t)\n",
    "        auc_curve.append(auc)\n",
    "    return np.array(auc_curve)\n",
    "\n",
    "def print_cindex_summary(name, scores):\n",
    "    print(f\"{name:<25} → C-index: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "def compare_models(cindex_a, cindex_b, name_a=\"A\", name_b=\"B\"):\n",
    "    stat, p = wilcoxon(cindex_a, cindex_b)\n",
    "    mean_diff = np.mean(np.array(cindex_b) - np.array(cindex_a))\n",
    "    print(f\"\\n Wilcoxon: {name_a} vs. {name_b}\")\n",
    "    print(f\"Mean difference: {mean_diff:.3f}\")\n",
    "    print(f\"p-value: {p:.4f}\")\n",
    "    if p < 0.05:\n",
    "        print(\"Statistically significant\")\n",
    "    else:\n",
    "        print(\"Not statistically significant\")\n",
    "\n",
    "# --- Few-shot TL Evaluation ---\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def run_fewshot_transfer_cv(source_df, target_df, source_name, target_name):\n",
    "    print(f\"\\n FEWSHOT TRANSFER (5-fold CV): {source_name} → {target_name}\")\n",
    "\n",
    "    X_source = to_X(source_df)\n",
    "    y_source = to_sksurv_y(source_df)\n",
    "    X_target = to_X(target_df)\n",
    "    y_target = to_sksurv_y(target_df)\n",
    "\n",
    "    ratios = [0.05, 0.10, 0.20]\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for ratio in ratios:\n",
    "        print(f\"\\n Ratio: {int(ratio*100)}%\")\n",
    "\n",
    "        c_base_all, c_trans_all, c_weighted_all = [], [], []\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(kf.split(X_target)):\n",
    "            X_train, X_test = X_target[train_idx], X_target[test_idx]\n",
    "            y_train, y_test = y_target[train_idx], y_target[test_idx]\n",
    "            y_events = y_train[\"event\"].astype(int)\n",
    "\n",
    "            # Few-shot sampling\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, train_size=ratio, random_state=fold)\n",
    "            few_idx, _ = next(sss.split(X_train, y_events))\n",
    "            X_fewshot, y_fewshot = X_train[few_idx], y_train[few_idx]\n",
    "\n",
    "            # --- Baseline ---\n",
    "            model_b = GradientBoostingSurvivalAnalysis(n_estimators=100, random_state=fold)\n",
    "            model_b.fit(X_fewshot, y_fewshot)\n",
    "            pred_b = model_b.predict(X_test)\n",
    "            c_b = concordance_index_censored(y_test[\"event\"], y_test[\"time\"], pred_b)[0]\n",
    "            c_base_all.append(c_b)\n",
    "\n",
    "            # --- Standard TL ---\n",
    "            model_s = GradientBoostingSurvivalAnalysis(n_estimators=100, warm_start=True, random_state=fold)\n",
    "            model_s.fit(X_source, y_source)\n",
    "            model_s.set_params(n_estimators=150)\n",
    "            model_s.fit(X_fewshot, y_fewshot)\n",
    "            pred_s = model_s.predict(X_test)\n",
    "            c_s = concordance_index_censored(y_test[\"event\"], y_test[\"time\"], pred_s)[0]\n",
    "            c_trans_all.append(c_s)\n",
    "\n",
    "            # --- Weighted TL ---\n",
    "            model_w = GradientBoostingSurvivalAnalysis(n_estimators=100, warm_start=True, random_state=fold)\n",
    "            model_w.fit(X_source, y_source)\n",
    "            model_w.set_params(n_estimators=150)\n",
    "            sample_weight = compute_sample_weight(class_weight={1: 5, 0: 1}, y=y_fewshot[\"event\"].astype(int))\n",
    "            model_w.fit(X_fewshot, y_fewshot, sample_weight=sample_weight)\n",
    "            pred_w = model_w.predict(X_test)\n",
    "            c_w = concordance_index_censored(y_test[\"event\"], y_test[\"time\"], pred_w)[0]\n",
    "            c_weighted_all.append(c_w)\n",
    "\n",
    "        # Print C-index results\n",
    "        print_cindex_summary(\"Baseline\", c_base_all)\n",
    "        print_cindex_summary(\"Standard TL\", c_trans_all)\n",
    "        print_cindex_summary(\"Weighted TL\", c_weighted_all)\n",
    "\n",
    "        # Wilcoxon comparisons\n",
    "        compare_models(c_base_all, c_trans_all, \"Baseline\", \"Standard TL\")\n",
    "        compare_models(c_base_all, c_weighted_all, \"Baseline\", \"Weighted TL\")\n",
    "        compare_models(c_trans_all, c_weighted_all, \"Standard TL\", \"Weighted TL\")\n",
    "\n",
    "        # Final model (for AUC plot)\n",
    "        model_b.fit(X_fewshot, y_fewshot)\n",
    "        model_s.fit(X_fewshot, y_fewshot)\n",
    "        model_w.fit(X_fewshot, y_fewshot, sample_weight=sample_weight)\n",
    "\n",
    "        eval_times = np.linspace(y_target[\"time\"].min(), y_target[\"time\"].max() - 1e-6, 50)\n",
    "        pred_auc_b = model_b.predict(X_target)\n",
    "        pred_auc_s = model_s.predict(X_target)\n",
    "        pred_auc_w = model_w.predict(X_target)\n",
    "\n",
    "        auc_b = compute_dynamic_auc_v(y_target, y_target, pred_auc_b, eval_times)\n",
    "        auc_s = compute_dynamic_auc_v(y_target, y_target, pred_auc_s, eval_times)\n",
    "        auc_w = compute_dynamic_auc_v(y_target, y_target, pred_auc_w, eval_times)\n",
    "\n",
    "        # Plot dynamic AUC\n",
    "        plt.figure(figsize=(10, 6), dpi=300)\n",
    "        plt.plot(eval_times, auc_b, label=\"Baseline\", marker='o')\n",
    "        plt.plot(eval_times, auc_s, label=\"Standard TL\", marker='s')\n",
    "        plt.plot(eval_times, auc_w, label=\"Weighted TL\", marker='^')\n",
    "        plt.axhline(0.5, ls='--', color='gray')\n",
    "        plt.title(f\"Few-Shot Transfer (CV) @ {int(ratio*100)}%: {source_name} → {target_name}\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Dynamic AUC\")\n",
    "        plt.ylim(0.3, 1.0)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a84cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " FEWSHOT TRANSFER (5-fold CV): India → Jordan\n",
      "\n",
      " Ratio: 5%\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Prepare combinations\n",
    "names = list(dataset_registry.keys())\n",
    "all_pairs = list(itertools.permutations(names, 2))\n",
    "\n",
    "# Run few-shot TL experiments for all pairs\n",
    "for source_name, target_name in all_pairs:\n",
    "    run_fewshot_transfer_cv(\n",
    "        dataset_registry[source_name],\n",
    "        dataset_registry[target_name],\n",
    "        source_name,\n",
    "        target_name\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec6760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
